{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.30\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "print(jax.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.841471  2.9092975 2.14112  ]\n"
     ]
    }
   ],
   "source": [
    "# create jax array/vector\n",
    "x = jax.numpy.array([1, 2, 3])\n",
    "\n",
    "# apply sine function to the array\n",
    "y = jax.numpy.sin(x) + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1.        1.4142135]\n",
      " [1.7320508 2.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Create jax matrix\n",
    "M = jax.numpy.array([[1, 2], [3, 4]])\n",
    "M_sqrt = jax.numpy.sqrt(M)\n",
    "print(M)\n",
    "print(M_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [1 2 3 4 5]\n",
      "A_sqr: [ 1  4  9 16 25]\n",
      "A_sqr_cumulative_sum: [ 1  5 14 30 55]\n",
      "A_sqr_cumulative_sum_mean: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Code challenge, location: 283\n",
    "def array_manipulation_challenge(A):\n",
    "  A_sqr = jax.numpy.square(A)\n",
    "  A_sqr_cumulative_sum = jax.numpy.cumsum(A_sqr)\n",
    "  A_sqr_cumulative_sum_mean = jax.numpy.mean(A_sqr_cumulative_sum)\n",
    "  return A_sqr, A_sqr_cumulative_sum, A_sqr_cumulative_sum_mean\n",
    "\n",
    "A = jax.numpy.array([1, 2, 3, 4, 5])\n",
    "A_sqr, A_sqr_cumulative_sum, A_sqr_cumulative_sum_mean = array_manipulation_challenge(A)\n",
    "\n",
    "print(f\"A: {A}\")\n",
    "print(f\"A_sqr: {A_sqr}\")\n",
    "print(f\"A_sqr_cumulative_sum: {A_sqr_cumulative_sum}\")\n",
    "print(f\"A_sqr_cumulative_sum_mean: {A_sqr_cumulative_sum_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is gradient:   \n",
    "https://www.youtube.com/watch?v=6zgBUZuC-p8&list=PLg5nrpKdkk2DpW_a-kuHU_FsVPPaU447J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at x=2.0: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Automatic Differentiation\n",
    "# Location 329\n",
    "# First code example\n",
    "import jax\n",
    "\n",
    "\"\"\"\n",
    "Jax's 'grad' function calculates the gradient of a function.\n",
    "The function takes two arguments:\n",
    "- the target function to calculate the gradient of\n",
    "- the index of the argument to calculate the gradient with respect to\n",
    "\n",
    "The result of this function ('jax.grad') is a new function ('simple_function_grad') that calculates the gradient of the target function with respect to the specified argument.\n",
    "The result of this new function is the derivative of the target function at the specified point.\n",
    "\"\"\"\n",
    "\n",
    "# define the target function to verify its gradient\n",
    "def simple_function(x):\n",
    "  return 2*x + 9\n",
    "  # return jax.numpy.sin(x)\n",
    "\n",
    "# calculate the gradient of the target function\n",
    "simple_function_grad = jax.grad(simple_function)\n",
    "\n",
    "# Evaluate the gradient at a specific point - the derivative of the function at that point\n",
    "result = simple_function_grad(2.0)  # 3.0 is the point at which the gradient is evaluated\n",
    "print(f\"Gradient at x=2.0: {result}\") # The derivative of the function at the specified point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized matrix multiplication: [[19 22]\n",
      " [43 50]]\n",
      "XLA optimized matrix multiplication: [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Matrix Multiplication using XLA\n",
    "\"\"\"\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "def mathmul(A, B):\n",
    "  return (A @ B)\n",
    "\n",
    "@jax.jit\n",
    "def mathmul_jit(A, B): \n",
    "  return (A @ B)\n",
    "\n",
    "A = jnp.array([[1, 2], [3, 4]])\n",
    "B = jnp.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Unoptimized matrix multiplication\n",
    "C = mathmul(A, B)\n",
    "print(f\"Unoptimized matrix multiplication: {C}\")\n",
    "\n",
    "# XLA optimized matrix multiplication\n",
    "D = mathmul_jit(A, B)\n",
    "print(f\"XLA optimized matrix multiplication: {D}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Timing and comparing functions\n",
    "\"\"\"\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "def compare(func, n, A, M):\n",
    "\n",
    "  def time_func(func, n, A, M):\n",
    "    for i in range(n):\n",
    "      M = func(A, M)\n",
    "      #print(f\"M: {M}\")\n",
    "    return(func)\n",
    "\n",
    "  # def time_func(func, n, A, M):\n",
    "  #   if n > 0:\n",
    "  #     new_M = func(A, M)\n",
    "  #     time_func(func, n-1, A, new_M)\n",
    "  #   return(func)\n",
    "\n",
    "  t1_start = perf_counter()\n",
    "  used_func = time_func(func, n, A, B)\n",
    "  print(f\"used_func: {used_func}\")\n",
    "  # Stop the stopwatch / counter\n",
    "  t1_stop = perf_counter()\n",
    "\n",
    "  return (t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used_func: <function mathmul at 0x7faa746222a0>\n",
      "used_func: <PjitFunction of <function mathmul_jit at 0x7faa74622520>>\n",
      "unoptimized_function_time: 3.3267515279999316 \n",
      "optimized_function_time: 2.424925336999877 \n",
      "Optimization value: 0.9018261910000547\n"
     ]
    }
   ],
   "source": [
    "A = jnp.array([[1, 2], [3, 4]])\n",
    "B = jnp.array([[5, 6], [7, 8]])\n",
    "n = 1000000\n",
    "\n",
    "unoptimized_function_time = compare(mathmul, n, A, B)\n",
    "optimized_function_time = compare(mathmul_jit, n, A, B)\n",
    "\n",
    "print(f\"unoptimized_function_time: {unoptimized_function_time} \")\n",
    "print(f\"optimized_function_time: {optimized_function_time} \")\n",
    "\n",
    "assert(optimized_function_time < unoptimized_function_time)\n",
    "print(f\"Optimization value: {unoptimized_function_time - optimized_function_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_p312_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
