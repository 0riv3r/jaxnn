{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH-7: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.31\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "print(jax.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generator for reproducibility\n",
    "jax.random.key(0)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "learning_rate = 0.01 # Hyperparameter for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample feature (house size) and target (house price) data\n",
    "house_sizes = jnp.array([1000., 1500., 2000., 2500., 3000.])\n",
    "prices = jnp.array([150000., 200000., 250000., 300000., 350000.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:  [0.57450044 0.09968603 0.39316022 0.8941783  0.59656656]\n",
      "Initial bias:  [0.41845703]\n"
     ]
    }
   ],
   "source": [
    "# Initialize random weights with a small range to avoid large initial errors\n",
    "weights = jax.random.uniform(key=jax.random.PRNGKey(0), shape=(5,))\n",
    "bias = jax.random.uniform(key=jax.random.PRNGKey(0), shape=(1,))\n",
    "print(\"Initial weights: \", weights)\n",
    "print(\"Initial bias: \", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(weights, inputs):\n",
    "    \"\"\"\n",
    "    Calculates the predicted value using the linear regression model\n",
    "    Args: \n",
    "      weights: a numpy array\n",
    "      inputs: a numpy array containing the feature values for a single data point.\n",
    "    Returns:\n",
    "      A 1D numpy array containing the predicted value.\n",
    "    \"\"\"\n",
    "    return jnp.dot(weights.T,inputs) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - MSE (Mean Squared Error)\n",
    "def mse_loss(predicted_prices, actual_prices):\n",
    "  \"\"\"\n",
    "  Calculates the mean squared error (MSE) loss between the predicted and actual prices\n",
    "  Args:\n",
    "    predicted_prices: a numpy array containing the predicted prices\n",
    "    actual_prices: a numpy array containing the actual prices\n",
    "  Returns:\n",
    "    A Numpy array containing the MSE loss.\n",
    "  \"\"\"\n",
    "  squared_errors = jnp.square(predicted_prices - actual_prices)\n",
    "  return jnp.mean(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gradient function of the loss function with respect to the weights\n",
    "loss_grad_fn = jax.grad(mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_prices: 5536.06982421875\n",
      "predicted_prices: 107796357120.0\n",
      "predicted_prices: -4.312263988294451e+16\n",
      "predicted_prices: 1.7250740009167372e+22\n",
      "predicted_prices: -6.900968278681468e+27\n",
      "predicted_prices: 2.760656424177989e+33\n",
      "predicted_prices: -inf\n",
      "predicted_prices: inf\n",
      "predicted_prices: nan\n",
      "predicted_prices: nan\n"
     ]
    }
   ],
   "source": [
    "# Training loop with manual gradient descent computation\n",
    "for _ in range(EPOCHS): # Train for EPOCHS epochs\n",
    "  # Forward pass: Calculates predicted prices using current weights\n",
    "  predicted_prices = linear_regression_model(weights, house_sizes)\n",
    "  print(f\"predicted_prices: {predicted_prices}\")\n",
    "  # Calculates the loss (MSE - Mean Square Error)\n",
    "  loss = mse_loss(predicted_prices=predicted_prices, actual_prices=prices)\n",
    "  # Calculates the gradients of the loss with respect to the weights (manual calculation)\n",
    "  # This is where automatic differentiation (autodiff) from jax would be useful.\n",
    "  gradients = 2*jnp.dot(house_sizes.T, (predicted_prices - prices)) / len(house_sizes)\n",
    "  #gradients = loss_grad_fn(predicted_prices, prices)\n",
    "  # Update the weights using gradient descent\n",
    "  weights = weights - learning_rate * gradients\n",
    "  # Print the loss after each epoch (optional) \n",
    "  # print(f\"Epoch: {_}, Loss: {loss:.4f}, gradients: {gradients}, weights: {weights}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
